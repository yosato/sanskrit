\documentclass{article}
\usepackage{coling2016}
\usepackage{amsmath}

%\usepackage[CJKspace]{XeCJK}
%\setCJKfamilyfont{zhrm}{SharpSong.ttf}
%\setCJKfamilyfont{jarm}{AozoraMinchoRegular.ttf}

\title{Clustering and adaptation of Japanese dialects: an unsupervised procedure}

\begin{document}

\maketitle

\begin{abstract}
  
\end{abstract}

\section{Introduction}

In what follows we propose a pipeline through which to derive a classified set of language models for dialects, given a body of `mixed' corpus composed of different dialects as yet unclassified, when one of them however is already sufficiently resourced. The main component of the proposal is an unsupervised clustering method to generate dialectal groupings. The test case we experiment on is Japanese, for which the `standard' dialect, the Tokyo variety, is sufficiently resourced, and hence equipped with an adequately working language model (we call these the `pivot' language and model).  Mature enough language models for dialects do not generally exist however, largely due to the insufficiency in dialect-classified data. Ironically enough this is despite the fact that the availability of dialect data has increased in the cyberspace, with the rise of social media and interactive message boards. It is principally the lack of classification that prevents the data from being utilised.

It can be said that the main reason for this absence of classified data is, in turn, the lack of an automatic classification procedure that does not require a human annotation. Comfounding the situation is the difficulty in demarcating different dialects, since the difference between neighbouring dialects is often not clear, showing a gradient nature. In an attempt to fill this lacuna, we propose that an unsupervised procedure is possible to cluster a mixed corpus into dialectal groupings in a flexible enough way that does not require hard classification, with the presence of a pivot dialect.

We report below that, starting from a mixed corpus containing various dialects of Japanese, where a pivot dialect exists, we achieve a clustring with  the accracy of  \%.  which also leads to the improvement of perplexity and prediction rate. one of which is sufficiently resourced. Taking this as the starting point, our task is to cluster the data into dialects, from which their sub-models are derived.

While we use a specific language as a test case, the envisaged scenario, and hence the motivation for this work, is an entirely general one. People tend to communicate in their dialect in an informal conversation, and this style of interlocution is prevalent in social media and text messages. If an automatic derivation of related dialects is made possible, this will greately to a wider utilisation of dialect data.

It is certainly the case that Japanese poses an additional challenge since there is no word segmentation in its orthography. This challenge however is a \emph{general} problem in language comprehension. Word segmentation simply is not present in speech, and is an artefact of some orthographies, to which the existence of non-segmented orthography ---there are a number of such languages globally--- is a testimony. Thus this property of Japanese makes the task more general in two senses: firstly its solution would subsume word-segmented languages, and also, it could eventually be developed to subsume the domain of speech. The task is like the one faced by a dialect monolingual who tries to understand a similar dialect, and for him/her, the difficulty is not so much with the unknown `words' as the incomprehensible `chunks' that may or may not correspond to words.

Our proposed procedure consists of three main stages. At the itinial stage, on the basis of the language model for the resourced dialect, we divide the corpus into two major sub-parts, the part likely to belong to the resourced dialect and everything else. On the latter `mixed bag' portion, the agglomerative clustering is performed to subdivide it into different dialects, based on the vocabulary similarity. Finally, the likely words specific to each dialect cluster are added to reconstruct the adapted model.

\section{Related work}

The present work can be categorised under the rubric of discrimination of similar languages (no strict distinction is possible after all between dialects and languages). Efforts have been made concerning the vaiant sets such as South-Asian languages (\cite{Ranaivo-Malancon06}), Slavic languages (\cite{}), English varieties (\cite{}) and Arabic  . These methods generally presuppose prior training with some reference classification, character-based N-gram () or  

\cite{}

Our overall scheme of using the pivot language for adaptation is inspired by the work relating to the concept of cognates \cite{Scherrer12}. As will be discussed, the last step will consist of roughly the same procedure to the one proposed by \cite{Scherrer12}. 


 and a new classification asis, and continues until   and build the    the classification is conducted by clustering, with the N-gram , where the corpus is sub-divided into dialects. We then have a second phase where the language , to derive the classified language model for each dialect, based on   one of which is already sufficiently `resourced,' the   and the language model of \emph{one} of these dialects, they are classified   a language model for each, in our case for Japanese.  and the lexicon of \emph{one} of these dialects.  OOV segmented corpus of  A word, or more precisely a word type, can be pronounced in various ways. In real life, the same sequence of phonemes are realised in a wide range of sounds, depending on various factors such as localib
ties, registers and individual habits, and this is sometimes reflected in their written forms. An emphasised and elongated `so good' may be written `soooo goooood' or a Cockney or French-accented `hello' may be written `'allo'. These variants essentially constitute the same word type, but to the  occasio and registers. This could in fact 

\cite{SaitoEtAl14}  a supervised method of


\section{Data}

We use two sets of data as inputs, controlled and natural. The first is the parallel dialect corpus recently published (Parallel Speech Corpora of Japanese Dialects, \cite{YoshinoEtAl16}: we only use the text part, henceforth PCJD), with five sets of 100 sentences that each represent a dialect (Tokyo, Tohoku, Kansai, San-yo and Kyushu) and contain the semantic equivalents (translations) with one another. Although the quantity of data is not realistic for training purposes, this dataset provides useful sources for tuning and evaluation. The other set is crawled Twitter data, obtained from the social media's official API, which amount to about 280 thousand sentences altogether. They were collected by setting geographical locations to the four areas represented in PCJD beside Tokyo. 

For each of the area-specific subdivisions in the Twitter data, we separated its first hundred genuinely dialectal sentences as a test set, varifying at the same time the proportion of such items. Importantly, the sentences coming from our non-pivot regions are not necessarily written in their dialect but in fact the majority is in the Tokyo dialect, perhaps reflecting the `public' nature of the social media. We asked four native speakers of respective non-Tokyo dialects to go through all the sentences until s/he reaches a hundred `undoubtedly' dialectal sentences and, for this portion, the Tokyoite of the authors judged if the ones not chosen were indistinguishable to the Tokyo dialect. The proportion between the Tokyo and local dialect turns out to be as shown in Table \label{}.

As can be seen, the proportion varies widely amongst the areas. The highest proportion is for the Kansai region at 12.6\%, which is followed by Kyushu and San-yo, and the Tohoku area trails only at 0.4\%.  


For Twitter data,is different   oku  for which each set representing a dialect and each n-th sentence in  for five dialects are present. 



\section{Methods}

As stated in the introduction, the overall procedure of our proposal consists in three stages, separation of the sentences deemed likely to be a dialect, clustering of this portion and creation of adapted subsidiary language models. In this section the details of each stage are described.



\subsection{Separation of dialect-like sentences}

At this initial stage we separate from the corpus the sentences which can potentially be dialects. Although we have so far talked loosely, as the target, of `dialect-like' sentences, what we mean more precisely is `anomolous' sentences relative to the resourced language model, that is, any sentence that the existent language model finds difficult to parse. Hence this is an attempt to narrow down on, and not entirely identifying, the candidates for dialect sentences. We first restrict the targets, and cluster only these targets, employing a two-pass strategy, rather than tackling the task in one go.

The adoption of this strategy warrants some justification for at least two reasons. One is that our candidates, if restricted, would inevitably contain false positives, anomolous but not dialectal sentences, such as ones with jargon or neologism. We will come back to this issue in the next section. The other reason is that the alternative of one-shot strategy may be considered viable. In fact it may be, depending on the amount of data, because the main concern in this regard is efficiency. As the choice of our clustering method, to be discussed again in the next section, is a relatively expensive one in terms of computation, it is better to keep the target datapoints small enough for tractability. Admittedly if the majority of the data is indeed anomolous relative to the existent language model, not much saving would be achieved, but this is not the case with our data. 

Furthermore, because the distance metric employed in this study is based on the sharing of improbability according to the pivot model, the  by definition assumption that low-probability items is is correct,  inert. the distance metric used for clustering is based on sharing of low-probability words. The assumption is that the lower the probability of a word is, the more anomolous it is. If we went about and clustered head-on without the first phase,   It is at least plausible on the other hand to say that this is closer to what (mono-dialectal) human native speakers generally do: judging if a sentence belongs to your dialect first, or rather,  

Such difficulty can come in two types, lexical and contextual, although they are interrelated. In Mecab, 

We then characterise `imporobability' of a word from two perspectives, contextual and lexical. Contexual probability  

\subsection{Clustering}

We adopt a hierarchical agglomerative clustering to find clusters for our sentences. First, those algorithms that require a numerical value for each datapoint (such as k-means) are not appropriate as there is no such obvious metric that appears relevant to dialect groupings. We only get probabilities obtained from the pivot language model, which may tell us about the difference between the pivot dialect and others, but not the differences amongst dialects. On the other hand, there is a fashion relevant to our target in which the distance between datapoints is calculated, as we shall see shortly, and this is precisely the sole requirement for hierarchical clustering. Further, another positive reason of this choice is the flexibility regarding the number of clusters. While we have the tentative target count of classes (four), this does not mean we have it as a hard target. We would not really mind after all if the number of clusters is larger, as long as there is no false positives: sentences of a single dialect class can belong perhaps to two clusters, if they do not mix with other dialects.

Furthermore, a cluster (or two) that belongs to no dialect is perfectly fine as well. In fact this is what we propose to address the issue of non-dialect anomaly we mentioned in the preceding section. That is, we expect to, or rather, design the distance metric in such a way to, have such anomaly assigned a cluster, or perhaps a few of them, of their own. As we shall see, this is broadly what we get as a result. 

The goal of the clustering therefore is 

\subsubsection{Distance metric}

As a distance metric required for agglomerative clustering, we propose one based on lexical sharing, which hinges on the following intuitions about dialects:

\begin{itemize}
\item{the most conspicuous sign (in text) of being a dialect is lexical anomaly from the pivot dialect  }
\item{a dialect has a consistent shared vocabulary, so two sentences that share anomalous lexical items are likely to belong to the same dialect}
\end{itemize}

Therefore, we base the distance of two sentences on the rate of sharing of improbable words between them. We call it a direct anomaly share ratio (DASR). It is characterised as the ratio of the count of shared anomalous word tokens (AWTokens) against the expected such count relative to the length.  which is the total count of tokens divided by the total count of anomalous tokens in the corpus. Thus for two sentences $S_1$ and $S_2$\footnote{the set notation}:

\begin{equation}
  \label{eq:1}
DASR(S_1,S_2)= \frac{|\{t|\text{{\it t} is an AWToken in } S_1\}\cap{}\{t|t \text{ is an AWToken in } S_2\}|}{ C(\text{all AWTokens})/C(\text{all tokens})\times min(len(S_1),len(S_2))} 
\end{equation}
 
We preface this rate with `direct' because it is about direct sharing of words, and is to be augmented by the indirect counterpart, indirect anomaly share rate or IASR. It is quite clearly inadequate to gauge the dialect membership on DISR alone, since many sentences within a single dialect would not share words directly. Nevertheless equi-dialectal sentences should form a network of indirect sharing, given the consistent vocabulary assumption above. Combined with  the following assumption,

\begin{itemize}
\item{a sentence only contains a single dialect in a sentence with the exception of the pivot dialect (people don't mix two different dialects except the standard variety)}
\end{itemize}

\noindent we would get:

\begin{itemize}
\item{two sentences whose anomolous items are shared by a third sentence is likely to belong to the same dialect}
\end{itemize}

For example, if a sentence contains an anomalous word A, and another anomolous word B, and there is a further sentence that contains both A and B, A and B are considered likely to belong to the same group on account of this indirect sharing, despite the absence of directly shared words between them. 

\begin{equation}
  \label{eq:2}
 IISR(S_1,S_2,S_3)= \begin{cases} mean( DISR(S_1,S_3), DISR(S_2,S_3) ) & \text{ if } DISR(S_1,S_3) \neq{} 0 \cap{} DISR(S_2,S_3) \neq{} 0   \\0 & \text{ otherwise} \end{cases}
\end{equation}

Given the possibility that there are multiple instances of the `third' sentences that share the same words with $S_1$ and $S_2$, we generalise $IISR$ as follows:

\begin{equation}
  \label{eq:3}
 IISR(S_1,S_2)= mean(\sigma ) 
\end{equation}


We then need to combine the direct and indirect metrics. It seems to make sense that direct sharing should carry more weight than indirect one. Also, one needs to take care of the cases in which both $DISR$ and $IISR$ are 0, which may occur particularly when the data is sparce.  



\section{Evaluation}



\section{Final remarks}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
